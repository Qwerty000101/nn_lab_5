{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppMRe6FjzmT1"
   },
   "source": [
    "1. Из ноутбуков по практике \"Рекуррентные и одномерные сверточные нейронные сети\" выберите лучшую сеть, либо создайте свою.\n",
    "2. Запустите раздел \"Подготовка\"\n",
    "3. Подготовьте датасет с параметрами `VOCAB_SIZE=20'000`, `WIN_SIZE=1000`, `WIN_HOP=100`, как в ноутбуке занятия, и обучите выбранную сеть. Параметры обучения можно взять из практического занятия. Для  всех обучаемых сетей в данной работе они должны быть одни и теже.\n",
    "4. Поменяйте размер словаря tokenaizera (`VOCAB_SIZE`) на `5000`, `10000`, `40000`.  Пересоздайте датасеты, при этом оставьте `WIN_SIZE=1000`, `WIN_HOP=100`.\n",
    "Обучите выбранную нейронку на этих датасетах.  Сделайте выводы об  изменении  точности распознавания авторов текстов. Результаты сведите в таблицу\n",
    "5. Поменяйте длину отрезка текста и шаг окна разбиения текста на векторы  (`WIN_SIZE`, `WIN_HOP`) используя значения (`500`,`50`) и (`2000`,`200`). Пересоздайте датасеты, при этом оставьте `VOCAB_SIZE=20000`. Обучите выбранную нейронку на этих датасетах. Сделайте выводы об  изменении точности распознавания авторов текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:47.830135Z",
     "iopub.status.busy": "2025-05-25T11:20:47.829305Z",
     "iopub.status.idle": "2025-05-25T11:20:47.838263Z",
     "shell.execute_reply": "2025-05-25T11:20:47.837454Z",
     "shell.execute_reply.started": "2025-05-25T11:20:47.830111Z"
    },
    "id": "NuefvFnfzoSq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Работа с массивами данных\n",
    "# Функции операционной системы\n",
    "import os\n",
    "# Регулярные выражения\n",
    "import re\n",
    "# Работа со временем\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "# Загрузка датасетов из облака google\n",
    "import gdown\n",
    "# Отрисовка графиков\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Вывод объектов в ячейке colab\n",
    "from IPython.display import display\n",
    "# Матрица ошибок классификатора\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Функции-утилиты для работы с категориальными данными\n",
    "from tensorflow.keras import utils\n",
    "# Основные слои\n",
    "from tensorflow.keras.layers import ( LSTM,BatchNormalization,\n",
    "                                     Bidirectional,  Dense, Dropout,\n",
    "                                     Embedding, \n",
    "                                     SpatialDropout1D)\n",
    "# Класс для конструирования последовательной модели нейронной сети\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Токенизатор для преобразование текстов в последовательности\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Рисование схемы модели\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для скачивания и распаковки датасета из облачного хранилища.\n",
    "Параметры:\n",
    "- url: URL архива с датасетом\n",
    "- output_dir: директория для сохранения распакованных файлов\n",
    "Действия:\n",
    "1. Создает директорию, если она не существует\n",
    "2. Скачивает архив по указанному URL\n",
    "3. Распаковывает архив в указанную директорию\n",
    "4. Удаляет скачанный архив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract(url, output_dir):\n",
    "    \"\"\"Скачивает и распаковывает архив с датасетом\"\"\"\n",
    "    # Создаем папку для данных, если ее нет\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Путь для сохранения архива\n",
    "    zip_path = os.path.join(output_dir, 'dataset.zip')\n",
    "    \n",
    "    # Скачиваем архив\n",
    "    print(\"Скачивание архива...\")\n",
    "    gdown.download(url, zip_path, quiet=False)\n",
    "    \n",
    "    # Распаковываем архив\n",
    "    print(\"Распаковка архива...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "    \n",
    "    # Удаляем архив\n",
    "    os.remove(zip_path)\n",
    "    print(\"Датасет готов к использованию\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка и распаковка датасета с текстами авторов.\n",
    "Используется функция download_and_extract с указанием:\n",
    "- URL архива в Yandex Cloud\n",
    "- Локальной директории 'writers' для сохранения файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:47.840160Z",
     "iopub.status.busy": "2025-05-25T11:20:47.839626Z",
     "iopub.status.idle": "2025-05-25T11:20:47.865208Z",
     "shell.execute_reply": "2025-05-25T11:20:47.864472Z",
     "shell.execute_reply.started": "2025-05-25T11:20:47.840136Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://storage.yandexcloud.net/aiueducation/Content/base/l7/writers.zip\n",
      "To: c:\\Users\\HAIER\\Desktop\\Задания\\Основы нейронных сетей\\Занятие 5\\nn_lab_5\\ДЗ\\writers\\dataset.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачивание архива...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.13M/8.13M [00:01<00:00, 4.41MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распаковка архива...\n",
      "Датасет готов к использованию\n"
     ]
    }
   ],
   "source": [
    "# Загрузка и распаковка архива\n",
    "download_and_extract('https://storage.yandexcloud.net/aiueducation/Content/base/l7/writers.zip', 'writers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройка констант для загрузки и обработки данных:\n",
    "- FILE_DIR: папка с текстовыми файлами\n",
    "- SIG_TRAIN: подстрока в имени файла, указывающая на обучающую выборку\n",
    "- SIG_TEST: подстрока в имени файла, указывающая на тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:47.866141Z",
     "iopub.status.busy": "2025-05-25T11:20:47.865982Z",
     "iopub.status.idle": "2025-05-25T11:20:47.869728Z",
     "shell.execute_reply": "2025-05-25T11:20:47.869031Z",
     "shell.execute_reply.started": "2025-05-25T11:20:47.866129Z"
    },
    "id": "qrEewtj70P9K",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Настройка констант для загрузки данных\n",
    "FILE_DIR  = 'writers'                     # Папка с текстовыми файлами\n",
    "SIG_TRAIN = 'обучающая'                   # Признак обучающей выборки в имени файла\n",
    "SIG_TEST  = 'тестовая'                    # Признак тестовой выборки в имени файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка текстовых данных из файлов и их разделение на обучающую и тестовую выборки.\n",
    "Алгоритм:\n",
    "1. Инициализация пустых списков для классов и текстов\n",
    "2. Получение списка файлов в директории\n",
    "3. Обработка каждого файла:\n",
    "   - Извлечение имени класса и типа выборки из имени файла\n",
    "   - Добавление нового класса в CLASS_LIST при необходимости\n",
    "   - Чтение содержимого файла\n",
    "   - Добавление текста в соответствующую выборку (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:47.871474Z",
     "iopub.status.busy": "2025-05-25T11:20:47.871279Z",
     "iopub.status.idle": "2025-05-25T11:20:48.067360Z",
     "shell.execute_reply": "2025-05-25T11:20:48.066781Z",
     "shell.execute_reply.started": "2025-05-25T11:20:47.871462Z"
    },
    "id": "icC2zaR10Spi",
    "outputId": "1919c3c9-86f9-4032-e8c7-f24af35d742d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавление класса \"Макс Фрай\"\n",
      "Добавление файла \"(Макс Фрай) Тестовая_2 вместе.txt\" в класс \"Макс Фрай\", тестовая выборка.\n",
      "Добавление класса \"Клиффорд_Саймак\"\n",
      "Добавление файла \"(Клиффорд_Саймак) Обучающая_5 вместе.txt\" в класс \"Клиффорд_Саймак\", обучающая выборка.\n",
      "Добавление класса \"Рэй Брэдберри\"\n",
      "Добавление файла \"(Рэй Брэдберри) Тестовая_8 вместе.txt\" в класс \"Рэй Брэдберри\", тестовая выборка.\n",
      "Добавление файла \"(Клиффорд_Саймак) Тестовая_2 вместе.txt\" в класс \"Клиффорд_Саймак\", тестовая выборка.\n",
      "Добавление файла \"(Макс Фрай) Обучающая_5 вместе.txt\" в класс \"Макс Фрай\", обучающая выборка.\n",
      "Добавление класса \"Стругацкие\"\n",
      "Добавление файла \"(Стругацкие) Обучающая_5 вместе.txt\" в класс \"Стругацкие\", обучающая выборка.\n",
      "Добавление класса \"О. Генри\"\n",
      "Добавление файла \"(О. Генри) Тестовая_20 вместе.txt\" в класс \"О. Генри\", тестовая выборка.\n",
      "Добавление класса \"Булгаков\"\n",
      "Добавление файла \"(Булгаков) Тестовая_2 вместе.txt\" в класс \"Булгаков\", тестовая выборка.\n",
      "Добавление файла \"(Рэй Брэдберри) Обучающая_22 вместе.txt\" в класс \"Рэй Брэдберри\", обучающая выборка.\n",
      "Добавление файла \"(О. Генри) Обучающая_50 вместе.txt\" в класс \"О. Генри\", обучающая выборка.\n",
      "Добавление файла \"(Булгаков) Обучающая_5 вместе.txt\" в класс \"Булгаков\", обучающая выборка.\n",
      "Добавление файла \"(Стругацкие) Тестовая_2 вместе.txt\" в класс \"Стругацкие\", тестовая выборка.\n"
     ]
    }
   ],
   "source": [
    "# Подготовим пустые списки\n",
    "\n",
    "CLASS_LIST = []  # Список классов\n",
    "text_train = []  # Список для оучающей выборки\n",
    "text_test = []   # Список для тестовой выборки\n",
    "\n",
    "# Получим списка файлов в папке\n",
    "file_list = os.listdir(FILE_DIR)\n",
    "\n",
    "for file_name in file_list:\n",
    "    # Выделяем имя класса и типа выборки из имени файла\n",
    "    m = re.match('\\((.+)\\) (\\S+)_', file_name)\n",
    "    # Если выделение получилось, то файл обрабатываем\n",
    "    if m:\n",
    "\n",
    "        # Получим имя класса\n",
    "        class_name = m[1]\n",
    "\n",
    "        # Получим имя выборки\n",
    "        subset_name = m[2].lower()\n",
    "\n",
    "        # Проверим тип выборки\n",
    "        is_train = SIG_TRAIN in subset_name\n",
    "        is_test = SIG_TEST in subset_name\n",
    "\n",
    "        # Если тип выборки обучающая либо тестовая - файл обрабатываем\n",
    "        if is_train or is_test:\n",
    "\n",
    "            # Добавляем новый класс, если его еще нет в списке\n",
    "            if class_name not in CLASS_LIST:\n",
    "                print(f'Добавление класса \"{class_name}\"')\n",
    "                CLASS_LIST.append(class_name)\n",
    "\n",
    "                # Инициализируем соответствующих классу строки текста\n",
    "                text_train.append('')\n",
    "                text_test.append('')\n",
    "\n",
    "            # Найдем индекс класса для добавления содержимого файла в выборку\n",
    "            cls = CLASS_LIST.index(class_name)\n",
    "            print(f'Добавление файла \"{file_name}\" в класс \"{CLASS_LIST[cls]}\", {subset_name} выборка.')\n",
    "\n",
    "            # Откроем файл на чтение\n",
    "            with open(f'{FILE_DIR}/{file_name}', 'r') as f:\n",
    "\n",
    "                # Загрузим содержимого файла в строку\n",
    "                text = f.read()\n",
    "            # Определим выборку, куда будет добавлено содержимое\n",
    "            subset = text_train if is_train else text_test\n",
    "\n",
    "            # Добавим текста к соответствующей выборке класса. Концы строк заменяются на пробел\n",
    "            subset[cls] += ' ' + text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение количества классов на основе загруженных данных.\n",
    "CLASS_COUNT будет использоваться при построении модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.068280Z",
     "iopub.status.busy": "2025-05-25T11:20:48.068026Z",
     "iopub.status.idle": "2025-05-25T11:20:48.072067Z",
     "shell.execute_reply": "2025-05-25T11:20:48.071292Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.068256Z"
    },
    "id": "hy_bWKK00Vaa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Определим количество классов\n",
    "CLASS_COUNT = len(CLASS_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод списка загруженных классов текстов для проверки корректности загрузки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.072884Z",
     "iopub.status.busy": "2025-05-25T11:20:48.072685Z",
     "iopub.status.idle": "2025-05-25T11:20:48.087652Z",
     "shell.execute_reply": "2025-05-25T11:20:48.087009Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.072870Z"
    },
    "id": "pSU_GesQ0X_r",
    "outputId": "46356542-6e8d-490d-a1ef-baeb8b91b226",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Макс Фрай', 'Клиффорд_Саймак', 'Рэй Брэдберри', 'Стругацкие', 'О. Генри', 'Булгаков']\n"
     ]
    }
   ],
   "source": [
    "# Выведем прочитанные классы текстов\n",
    "print(CLASS_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка количества текстов в обучающей выборке.\n",
    "Должно соответствовать количеству классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.088570Z",
     "iopub.status.busy": "2025-05-25T11:20:48.088321Z",
     "iopub.status.idle": "2025-05-25T11:20:48.102661Z",
     "shell.execute_reply": "2025-05-25T11:20:48.101964Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.088549Z"
    },
    "id": "DrtrxcG60bdM",
    "outputId": "49cc6bdf-81b3-4bbb-b38d-4f203b959c21",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем количество текстов в обучающей выборке\n",
    "print(len(text_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка загруженных данных: вывод начальных фрагментов текстов \n",
    "из каждого класса для обучающей и тестовой выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.104503Z",
     "iopub.status.busy": "2025-05-25T11:20:48.104318Z",
     "iopub.status.idle": "2025-05-25T11:20:48.117160Z",
     "shell.execute_reply": "2025-05-25T11:20:48.116566Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.104490Z"
    },
    "id": "7FaTm0Ef0d3C",
    "outputId": "de595fb9-aeb3-483a-b3df-b1848f7fb19c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс: Макс Фрай\n",
      "  train:  ﻿Власть несбывшегося   – С тех пор как меня угораздило побывать в этой грешной Черхавле, мне ежедневно снится какая-то дичь! – сердито сказал я Джуффину. – Сглазили они меня, что ли? А собственно, по\n",
      "  test :  ﻿Слишком много кошмаров    Когда балансируешь над пропастью на узкой, скользкой от крови доске, ответ на закономерный вопрос: «Как меня сюда занесло?» – вряд ли принесёт практическую пользу. Зато пои\n",
      "\n",
      "Класс: Клиффорд_Саймак\n",
      "  train:  ﻿Всё живое...     Когда я выехал из нашего городишка и повернул на шоссе, позади оказался грузовик. Этакая тяжелая громадина с прицепом, и неслась она во весь дух. Шоссе здесь срезает угол городка, и\n",
      "  test :  ﻿Зачарованное паломничество    1  Гоблин со стропил следил за прячущимся монахом, который шпионил за ученым. Гоблин ненавидел монаха и имел для этого все основания. Монах никого не ненавидел и не люб\n",
      "\n",
      "Класс: Рэй Брэдберри\n",
      "  train:  ﻿451° по Фаренгейту   ДОНУ КОНГДОНУ С БЛАГОДАРНОСТЬЮ   Если тебе дадут линованную бумагу, пиши поперёк.  Хуан Рамон Хименес   Часть 1  ОЧАГ И САЛАМАНДРА   Жечь было наслаждением. Какое-то особое насл\n",
      "  test :  ﻿Марсианские хроники   МОЕЙ ЖЕНЕ МАРГАРЕТ С ИСКРЕННЕЙ ЛЮБОВЬЮ   «Великое дело – способность удивляться, – сказал философ. – Космические полеты снова сделали всех нас детьми».   Январь 1999  Ракетное \n",
      "\n",
      "Класс: Стругацкие\n",
      "  train:  Парень из преисподней     1     Ну и деревня! Сроду я таких деревень не видел и не знал даже, что такие деревни бывают. Дома круглые, бурые, без окон, торчат на сваях, как сторожевые вышки, а под ним\n",
      "  test :  ﻿ОТЕЛЬ «У ПОГИБШЕГО АЛЬПИНИСТА»    ГЛАВА 1     Я остановил машину, вылез и снял черные очки. Все было так, как рассказывал Згут. Отель был двухэтажный, желтый с зеленым, над крыльцом красовалась трау\n",
      "\n",
      "Класс: О. Генри\n",
      "  train:  «Лиса-на-рассвете»   Коралио нежился в полуденном зное, как томная красавица в сурово хранимом гареме. Город лежал у самого моря на полоске наносной земли. Он казался брильянтиком, вкрапленным в ярко\n",
      "  test :  ﻿Багдадская птица   Без всякого сомнения, дух и гений калифа Гаруна аль-Рашида осенил маркграфа Августа-Михаила фон Паульсена Квигга.  Ресторан Квигга находится на Четвертой авеню — на улице, которую\n",
      "\n",
      "Класс: Булгаков\n",
      "  train:  ﻿Белая гвардия   Посвящается[1]  Любови Евгеньевне Белозерской[2]  Пошел мелкий снег и вдруг повалил хло-  пьями. Ветер завыл; сделалась метель.  В одно мгновение темное небо смешалось с  снежным мор\n",
      "  test :  ﻿Дон Кихот ДЕЙСТВУЮЩИЕ ЛИЦА Алонсо Кихано, он же Дон Кихот Ламанчский.  Антония – его племянница.  Ключница Дон Кихота.  Санчо Панса – оруженосец Дон Кихота.  Перо Перес – деревенский священник, лице\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверим загрузки: выведем начальные отрывки из каждого класса\n",
    "\n",
    "for cls in range(CLASS_COUNT):                   # Запустим цикл по числу классов\n",
    "    print(f'Класс: {CLASS_LIST[cls]}')           # Выведем имя класса\n",
    "    print(f'  train: {text_train[cls][:200]}')   # Выведем фрагмент обучающей выборки\n",
    "    print(f'  test : {text_test[cls][:200]}')    # Выведем фрагмент тестовой выборки\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Контекстный менеджер для измерения времени выполнения операций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.118274Z",
     "iopub.status.busy": "2025-05-25T11:20:48.117982Z",
     "iopub.status.idle": "2025-05-25T11:20:48.130057Z",
     "shell.execute_reply": "2025-05-25T11:20:48.129380Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.118248Z"
    },
    "id": "HRgjpsx00e16",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Контекстный менеджер для измерения времени операций\n",
    "# Операция обертывается менеджером с помощью оператора with\n",
    "\n",
    "class timex:\n",
    "    def __enter__(self):\n",
    "        # Фиксация времени старта процесса\n",
    "        self.t = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        # Вывод времени работы\n",
    "        print('Время обработки: {:.2f} с'.format(time.time() - self.t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение параметров для экспериментов:\n",
    "- VOCAB_SIZES: размеры словаря для токенизатора\n",
    "- WIN_SIZES: размеры окон для сегментации текста\n",
    "- WIN_HOPS: шаги окон для сегментации текста\n",
    "- EPOCHS: количество эпох обучения\n",
    "- BATCH_SIZE: размер батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.131160Z",
     "iopub.status.busy": "2025-05-25T11:20:48.130908Z",
     "iopub.status.idle": "2025-05-25T11:20:48.145777Z",
     "shell.execute_reply": "2025-05-25T11:20:48.145206Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.131134Z"
    },
    "id": "UWVbqChC5-Y4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZES = [5000, 10000, 20000, 40000]  # изменение размера словаря токенизатора\n",
    "WIN_SIZES = [1000, 500, 2000]   # Размеры окна сегментации текста\n",
    "WIN_HOPS  = [100, 50, 200]  # Шаг окна сегментации текста\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подготовки датасета с заданными параметрами.\n",
    "Параметры:\n",
    "- vocab_size: размер словаря токенизатора\n",
    "- win_size: размер окна сегментации текста\n",
    "- win_hop: шаг окна сегментации текста\n",
    "\n",
    "Возвращает:\n",
    "- X_train, X_test: последовательности для обучающей и тестовой выборок\n",
    "- y_train, y_test: метки классов в one-hot формате\n",
    "- tokenizer: обученный токенизатор\n",
    "\n",
    "Алгоритм:\n",
    "1. Создание и обучение токенизатора\n",
    "2. Разбивка текстов на последовательности фиксированной длины\n",
    "3. Преобразование меток классов в one-hot формат\n",
    "4. Добавление паддинга к последовательностям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.146506Z",
     "iopub.status.busy": "2025-05-25T11:20:48.146354Z",
     "iopub.status.idle": "2025-05-25T11:20:48.156392Z",
     "shell.execute_reply": "2025-05-25T11:20:48.155797Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.146494Z"
    },
    "id": "Xt2Oh4Pb6BGW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Функция подготовки датасета\n",
    "# Подготовка датасета с разными VOCAB_SIZE, WIN_SIZE, WIN_HOP.\n",
    "def prepare_dataset(vocab_size, win_size, win_hop):\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(text_train + text_test)\n",
    "\n",
    "    # Разбивка текста на отрезки фиксированной длины с заданным шагом.\n",
    "    # Реализация параметров WIN_SIZE, WIN_HOP.\n",
    "    def split_texts(texts):\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        for idx, text in enumerate(texts):\n",
    "            seq = tokenizer.texts_to_sequences([text])[0]\n",
    "            for i in range(0, len(seq) - win_size, win_hop):\n",
    "                chunk = seq[i:i+win_size]\n",
    "                sequences.append(chunk)\n",
    "                labels.append(idx)\n",
    "        return sequences, labels\n",
    "\n",
    "    # Подготовка входных и выходных данных\n",
    "    # Паддинг последовательностей и one-hot-кодировка меток.\n",
    "    X_train, y_train = split_texts(text_train)\n",
    "    X_test, y_test = split_texts(text_test)\n",
    "\n",
    "    X_train = pad_sequences(X_train, maxlen=win_size)\n",
    "    X_test = pad_sequences(X_test, maxlen=win_size)\n",
    "\n",
    "    y_train = utils.to_categorical(y_train, CLASS_COUNT)\n",
    "    y_test = utils.to_categorical(y_test, CLASS_COUNT)\n",
    "\n",
    "    return np.array(X_train), np.array(X_test), y_train, y_test, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для создания модели нейронной сети.\n",
    "Архитектура:\n",
    "1. Embedding слой для преобразования токенов в векторы\n",
    "2. SpatialDropout1D для регуляризации\n",
    "3. BatchNormalization для нормализации активаций\n",
    "4. Два Bidirectional LSTM слоя для обработки последовательностей\n",
    "5. Dropout для регуляризации\n",
    "6. Dense слой с softmax активацией для классификации\n",
    "\n",
    "Параметры:\n",
    "- VOCAB_SIZE: размер словаря\n",
    "- WIN_SIZE: длина входных последовательностей\n",
    "\n",
    "Возвращает скомпилированную модель с оптимизатором Adam и метрикой accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.157486Z",
     "iopub.status.busy": "2025-05-25T11:20:48.157202Z",
     "iopub.status.idle": "2025-05-25T11:20:48.173835Z",
     "shell.execute_reply": "2025-05-25T11:20:48.173303Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.157462Z"
    },
    "id": "rH4fgRBiDAik",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_model(VOCAB_SIZE, WIN_SIZE):\n",
    "    model_LSTM_7 = Sequential()\n",
    "    model_LSTM_7.add(Embedding(VOCAB_SIZE, 50, input_length=WIN_SIZE))\n",
    "    model_LSTM_7.add(SpatialDropout1D(0.4))\n",
    "    model_LSTM_7.add(BatchNormalization())\n",
    "    # Два двунаправленных рекуррентных слоя LSTM\n",
    "    model_LSTM_7.add(Bidirectional(LSTM(8, return_sequences=True)))\n",
    "    model_LSTM_7.add(Bidirectional(LSTM(8)))\n",
    "    model_LSTM_7.add(Dropout(0.3))\n",
    "    model_LSTM_7.add(Dense(CLASS_COUNT, activation='softmax'))\n",
    "    model_LSTM_7.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model_LSTM_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эксперимент с разными размерами словаря (VOCAB_SIZE).\n",
    "Алгоритм:\n",
    "1. Для каждого размера словаря из VOCAB_SIZES:\n",
    "   - Подготовка датасета с фиксированными WIN_SIZE=1000 и WIN_HOP=100\n",
    "   - Построение и обучение модели\n",
    "   - Оценка точности на тестовой выборке\n",
    "   - Сохранение результатов\n",
    "2. Вывод таблицы с результатами\n",
    "\n",
    "Используется контекстный менеджер timex для измерения времени выполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.174908Z",
     "iopub.status.busy": "2025-05-25T11:20:48.174556Z",
     "iopub.status.idle": "2025-05-25T11:28:16.838807Z",
     "shell.execute_reply": "2025-05-25T11:28:16.838070Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.174883Z"
    },
    "id": "KVo8aCqLGOFV",
    "outputId": "8db08d8d-4205-4f52-92fb-5953731fc255",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== VOCAB_SIZE = 5000 ===\n",
      "Accuracy: 0.4462\n",
      "Время обработки: 112.02 с\n",
      "\n",
      "\n",
      "=== VOCAB_SIZE = 10000 ===\n",
      "Accuracy: 0.5296\n",
      "Время обработки: 111.22 с\n",
      "\n",
      "\n",
      "=== VOCAB_SIZE = 20000 ===\n",
      "Accuracy: 0.3670\n",
      "Время обработки: 112.54 с\n",
      "\n",
      "\n",
      "=== VOCAB_SIZE = 40000 ===\n",
      "Accuracy: 0.4945\n",
      "Время обработки: 112.87 с\n",
      "\n",
      "Точность для разных размеров словаря:\n",
      "VOCAB_SIZE=5000   --> Accuracy=0.4462\n",
      "VOCAB_SIZE=10000  --> Accuracy=0.5296\n",
      "VOCAB_SIZE=20000  --> Accuracy=0.3670\n",
      "VOCAB_SIZE=40000  --> Accuracy=0.4945\n"
     ]
    }
   ],
   "source": [
    "results_vocab = []\n",
    "\n",
    "# Задание: VOCAB_SIZE изменение\n",
    "for vocab_size in VOCAB_SIZES:\n",
    "    print(f'\\n\\n=== VOCAB_SIZE = {vocab_size} ===')\n",
    "    with timex():\n",
    "        X_train, X_test, y_train, y_test, _ = prepare_dataset(vocab_size, 1000, 100)\n",
    "        model = build_model(vocab_size, 1000)\n",
    "        history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                            validation_data=(X_test, y_test), verbose=0)\n",
    "        acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "        results_vocab.append((vocab_size, acc))\n",
    "        print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "# Таблица результатов по VOCAB_SIZE\n",
    "print(\"\\nТочность для разных размеров словаря:\")\n",
    "for vocab_size, acc in results_vocab:\n",
    "    print(f'VOCAB_SIZE={vocab_size:<6} --> Accuracy={acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эксперимент с разными параметрами окон (WIN_SIZE, WIN_HOP).\n",
    "Алгоритм:\n",
    "1. Для каждой пары (WIN_SIZE, WIN_HOP):\n",
    "   - Подготовка датасета с фиксированным VOCAB_SIZE=20000\n",
    "   - Построение и обучение модели\n",
    "   - Оценка точности на тестовой выборке\n",
    "   - Сохранение результатов\n",
    "2. Вывод таблицы с результатами\n",
    "\n",
    "Используется контекстный менеджер timex для измерения времени выполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-25T11:28:16.840304Z",
     "iopub.status.busy": "2025-05-25T11:28:16.839734Z",
     "iopub.status.idle": "2025-05-25T11:32:05.315216Z",
     "shell.execute_reply": "2025-05-25T11:32:05.314502Z",
     "shell.execute_reply.started": "2025-05-25T11:28:16.840284Z"
    },
    "id": "rCSvByMlGeDp",
    "outputId": "93d56ab9-5bc1-450c-b7d2-284867cb3268",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== WIN_SIZE = 500, WIN_HOP = 50 ===\n",
      "Accuracy: 0.5372\n",
      "Время обработки: 120.82 с\n",
      "\n",
      "\n",
      "=== WIN_SIZE = 2000, WIN_HOP = 200 ===\n",
      "Accuracy: 0.3548\n",
      "Время обработки: 107.65 с\n",
      "\n",
      "Точность для разных параметров окна:\n",
      "WIN_SIZE=500  , WIN_HOP=50   --> Accuracy=0.5372\n",
      "WIN_SIZE=2000 , WIN_HOP=200  --> Accuracy=0.3548\n"
     ]
    }
   ],
   "source": [
    "results_win = []\n",
    "\n",
    "for win_size, win_hop in [(500,50), (2000,200)]:\n",
    "    print(f'\\n\\n=== WIN_SIZE = {win_size}, WIN_HOP = {win_hop} ===')\n",
    "    with timex():\n",
    "        X_train, X_test, y_train, y_test, _ = prepare_dataset(20000, win_size, win_hop)\n",
    "        model = build_model(20000, win_size)\n",
    "        history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                            validation_data=(X_test, y_test), verbose=0)\n",
    "        acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "        results_win.append((win_size, win_hop, acc))\n",
    "        print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "# Таблица результатов по WIN_SIZE/WIN_HOP\n",
    "print(\"\\nТочность для разных параметров окна:\")\n",
    "for win_size, win_hop, acc in results_win:\n",
    "    print(f'WIN_SIZE={win_size:<5}, WIN_HOP={win_hop:<4} --> Accuracy={acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7508987,
     "sourceId": 11944534,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Neural_Networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
